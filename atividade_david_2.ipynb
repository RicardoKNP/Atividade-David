{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando os Pacotes que seram usandos e os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "# Definir o caminho do arquivo CSV\n",
    "labevents_path = r'C:\\Users\\ricak\\OneDrive\\Área de Trabalho\\Projeto deyvid\\mimic-iii-clinical-database-demo-1.4\\LABEVENTS.csv'\n",
    "labitems_path = r'C:\\Users\\ricak\\OneDrive\\Área de Trabalho\\Projeto deyvid\\mimic-iii-clinical-database-demo-1.4\\D_LABITEMS.csv'\n",
    "admissions_path = r'C:\\Users\\ricak\\OneDrive\\Área de Trabalho\\Projeto deyvid\\mimic-iii-clinical-database-demo-1.4\\ADMISSIONS.csv'\n",
    "patients_path = r'C:\\Users\\ricak\\OneDrive\\Área de Trabalho\\Projeto deyvid\\mimic-iii-clinical-database-demo-1.4\\PATIENTS.csv'\n",
    "# nome_diagnoses_path = r'C:\\Users\\ricak\\OneDrive\\Área de Trabalho\\Projeto deyvid\\mimic-iii-clinical-database-demo-1.4\\D_ICD_DIAGNOSES.csv'\n",
    "# diagnoses_path = r'C:\\Users\\ricak\\OneDrive\\Área de Trabalho\\Projeto deyvid\\mimic-iii-clinical-database-demo-1.4\\DIAGNOSES_ICD.csv'\n",
    "# drgcodes_path = r'C:\\Users\\ricak\\OneDrive\\Área de Trabalho\\Projeto deyvid\\mimic-iii-clinical-database-demo-1.4\\DRGCODES.csv'\n",
    "# microbiologyevents_path = r'C:\\Users\\ricak\\OneDrive\\Área de Trabalho\\Projeto deyvid\\mimic-iii-clinical-database-demo-1.4\\MICROBIOLOGYEVENTS.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando os arquivos em chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o tamanho dos chunks\n",
    "chunk_size = 1000\n",
    "\n",
    "# Lista para armazenar os dados filtrados\n",
    "dados_filtrados_labevents = []\n",
    "dados_filtrados_labitems = []\n",
    "dados_filtrados_admissions = []\n",
    "dados_filtrados_patients = []\n",
    "# dados_filtrados_nome_diagnoses = []\n",
    "# dados_filtrados_diagnoses = []\n",
    "# dados_filtrados_drgcodes = []\n",
    "# dados_filtrados_microbiologyevents = []\n",
    "\n",
    "# Ler LABEVENTS em chunks e processar cada chunk\n",
    "for labevents_chunk in pd.read_csv(labevents_path, chunksize=chunk_size):\n",
    "   \n",
    "     # Adicionar o chunk filtrado à lista\n",
    "    dados_filtrados_labevents.append(labevents_chunk)\n",
    "\n",
    "# Ler D_LABITEMS em chunks e processar cada chunk\n",
    "for labitems_chunk in pd.read_csv(labitems_path, chunksize=chunk_size):\n",
    "    \n",
    "        dados_filtrados_labitems.append(labitems_chunk)\n",
    "\n",
    "# Ler ADMISSIONS em chunks e processar cada chunk\n",
    "for admissions_chunk in pd.read_csv(admissions_path, chunksize=chunk_size):\n",
    "    \n",
    "        dados_filtrados_admissions.append(admissions_chunk)\n",
    "\n",
    "# Ler PATIENTS em chunks e processar cada chunk\n",
    "for patients_chunk in pd.read_csv(patients_path, chunksize=chunk_size):\n",
    "    \n",
    "        dados_filtrados_patients.append(patients_chunk)\n",
    "\n",
    "# Ler NOME_DIAGNOSES em chunks e processar cada chunk\n",
    "# for nome_diagnoses_chunk in pd.read_csv(nome_diagnoses_path, chunksize=chunk_size):\n",
    "    \n",
    "#         dados_filtrados_nome_diagnoses.append(nome_diagnoses_chunk)\n",
    "\n",
    "# # Ler DIAGNOSES em chunks e processar cada chunk\n",
    "# for diagnoses_chunk in pd.read_csv(diagnoses_path, chunksize=chunk_size):\n",
    "    \n",
    "#         dados_filtrados_diagnoses.append(diagnoses_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirando as colunas das tabelas usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado_labevents = pd.concat(dados_filtrados_labevents, ignore_index=True)\n",
    "\n",
    "df_filtrado_labitems = pd.concat(dados_filtrados_labitems, ignore_index=True)\n",
    "\n",
    "df_filtrado_admissions = pd.concat(dados_filtrados_admissions, ignore_index=True)\n",
    "\n",
    "df_filtrado_patients = pd.concat(dados_filtrados_patients, ignore_index=True)\n",
    "\n",
    "# df_filtrado_2 = pd.concat(dados_filtrados_nome_diagnoses, ignore_index=True)\n",
    "\n",
    "# df_filtrado_4 = pd.concat(dados_filtrados_diagnoses, ignore_index=True)\n",
    "\n",
    " #retirar a coluna 'row_id'\n",
    "\n",
    "df_filtrado_labevents = df_filtrado_labevents.drop(columns=['row_id', 'charttime','hadm_id','value'])\n",
    "\n",
    "df_filtrado_labitems = df_filtrado_labitems.drop(columns=['row_id','loinc_code'])\n",
    "\n",
    "df_filtrado_admissions = df_filtrado_admissions.drop(columns=['row_id', 'admittime','dischtime','insurance','hadm_id','deathtime','admission_type','admission_location','discharge_location','edregtime','edouttime','has_chartevents_data'])\n",
    "\n",
    "df_filtrado_patients = df_filtrado_patients.drop(columns=['row_id','expire_flag','dob','dod','dod_hosp','dod_ssn'])\n",
    "\n",
    "# df_filtrado_2 = df_filtrado_2.drop(columns=['row_id','long_title'])\n",
    "\n",
    "# df_filtrado_4 = df_filtrado_4.drop(columns=['row_id','seq_num','hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vendo quais são as variáveis que são não numéricas na coluna value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Supondo que seu DataFrame se chame 'df' e possua as colunas 'itemid' e 'value'\n",
    "# # Carregar o DataFrame (ajuste para o seu caminho e arquivo)\n",
    "# # df = pd.read_csv('seu_arquivo.csv')\n",
    "\n",
    "# # Defina o itemid que você deseja investigar\n",
    "# itemid_interesse = 51137\n",
    "\n",
    "# # Filtrar o DataFrame para incluir apenas as linhas com o itemid desejado\n",
    "# df_filtrado = Tabela_final[Tabela_final['itemid'] == itemid_interesse]\n",
    "\n",
    "# # Filtrar apenas os valores não numéricos na coluna 'value'\n",
    "# # Usamos a função `str.isnumeric` para identificar valores que não sejam números\n",
    "# # `~` é o operador de negação para inverter a condição\n",
    "# valores_nao_numericos = df_filtrado[~df_filtrado['value'].str.isnumeric()]\n",
    "\n",
    "# # Ver as variáveis categóricas distintas presentes na coluna 'value' para o itemid desejado\n",
    "# variaveis_categoricas = valores_nao_numericos['value'].unique()\n",
    "\n",
    "# # Exibir o resultado\n",
    "# print(f\"Valores categóricos para o itemid {itemid_interesse}:\")\n",
    "# print(variaveis_categoricas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo a Normalização dos dados por meio de min e max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Verificar se a coluna 'valuenum' tem valores numéricos e não nulos antes da normalização\n",
    "if 'valuenum' in df_filtrado_labevents:\n",
    "    # Substituir valores NaN por zero ou outro valor de sua escolha, se necessário:\n",
    "    df_filtrado_labevents['valuenum'] = df_filtrado_labevents['valuenum'].fillna(0)\n",
    "    \n",
    "    # Aplicar o scaler e transformar os valores para a escala entre 0 e 1\n",
    "    df_filtrado_labevents['valuenum_normalized'] = scaler.fit_transform(df_filtrado_labevents[['valuenum']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntando as tabelas em uma única"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazer a junção das tabelas\n",
    "\n",
    "Junto_1 = pd.merge(df_filtrado_labevents, df_filtrado_labitems, on='itemid', how='inner')\n",
    "\n",
    "Junto_2 = pd.merge(df_filtrado_admissions, df_filtrado_patients, on='subject_id', how='inner')\n",
    "\n",
    "Tabela_final = pd.merge(Junto_1, Junto_2, on='subject_id', how='inner')\n",
    "\n",
    "# Junto_4 = pd.merge(Junto_3, df_filtrado_4, on='subject_id', how='inner')\n",
    "\n",
    "# Tabela_final = pd.merge(Junto_4, df_filtrado_2, on='icd9_code', how='inner')\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Criar a tabela PrettyTable\n",
    "table = PrettyTable()\n",
    "\n",
    "# Adicionar os nomes das colunas\n",
    "table.field_names = Tabela_final.columns\n",
    "\n",
    "# Adicionar as linhas à tabela\n",
    "for row in Tabela_final.itertuples(index=False):\n",
    "    table.add_row(row)\n",
    "\n",
    "# # # Retorna um DataFrame com os valores únicos da coluna\n",
    "# valores_unicos_df = Tabela_final['valueuom'].drop_duplicates()\n",
    "# valores_unicos_df.to_csv('valores_unicos.csv', index=False)\n",
    "\n",
    "# print(valores_unicos_df)\n",
    "\n",
    "# SELECT itemid, label, valueuom FROM Tabela_final WHERE itemid = 50868\n",
    "\n",
    "\n",
    "# valores_unicos_df = pd.DataFrame(table.rows, columns=table.field_names)\n",
    "# valores_unicos_df.to_csv('valores_unicos.csv', index=False)\n",
    "\n",
    "# pd.set_option('display.max_rows', None)  # None para mostrar todas as linhas\n",
    "# pd.set_option('display.max_columns', None)  # None para mostrar todas as colunas\n",
    "\n",
    "# # Retorna um DataFrame com os valores únicos da coluna\n",
    "# valores_unicos_df = Tabela_final['valuenum'].value_counts()\n",
    "# print(valores_unicos_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olhando quais valores estão ausentes na tabela e as diferentes unidades de medida\n",
    "\n",
    "#Retirando os valores ausentes, ou seja, os exames que possuem apenas valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados agrupados que possuem média igual a 0: [50800, 50812, 50827, 50828, 50854, 50855, 50857, 50871, 50873, 50874, 50876, 50879, 50880, 50887, 50919, 50920, 50932, 50933, 50937, 50939, 50940, 50941, 50942, 50943, 50944, 50946, 50948, 50955, 50975, 50979, 50981, 50999, 51017, 51071, 51073, 51074, 51075, 51076, 51079, 51086, 51090, 51091, 51092, 51098, 51103, 51134, 51137, 51145, 51147, 51150, 51151, 51152, 51154, 51155, 51156, 51158, 51159, 51164, 51167, 51168, 51177, 51178, 51182, 51183, 51184, 51188, 51191, 51192, 51193, 51197, 51198, 51211, 51213, 51216, 51217, 51219, 51230, 51233, 51234, 51235, 51236, 51238, 51239, 51243, 51246, 51247, 51252, 51260, 51262, 51264, 51266, 51267, 51268, 51278, 51287, 51290, 51292, 51294, 51296, 51299, 51303, 51305, 51306, 51307, 51309, 51310, 51313, 51314, 51315, 51317, 51319, 51320, 51321, 51323, 51324, 51325, 51326, 51328, 51331, 51332, 51333, 51334, 51335, 51336, 51337, 51338, 51339, 51340, 51341, 51342, 51373, 51388, 51398, 51399, 51400, 51402, 51404, 51411, 51412, 51416, 51420, 51423, 51424, 51425, 51426, 51460, 51462, 51463, 51464, 51466, 51469, 51474, 51486, 51487, 51489, 51497, 51505, 51506, 51508, 51512, 51513, 51517, 51518, 51519, 51523, 51537]\n",
      "Dados agrupados que não possuem unidade de medida: [50800, 50812, 50819, 50823, 50825, 50826, 50827, 50828, 50854, 50855, 50857, 50871, 50873, 50874, 50876, 50879, 50880, 50887, 50919, 50920, 50932, 50933, 50939, 50940, 50941, 50942, 50943, 50944, 50948, 50955, 50975, 50979, 50999, 51017, 51071, 51074, 51075, 51079, 51086, 51087, 51090, 51091, 51092, 51094, 51103, 51134, 51137, 51145, 51147, 51150, 51151, 51152, 51154, 51155, 51156, 51158, 51159, 51164, 51167, 51168, 51177, 51182, 51183, 51184, 51188, 51191, 51192, 51193, 51197, 51198, 51216, 51217, 51219, 51230, 51233, 51234, 51235, 51236, 51237, 51238, 51239, 51240, 51243, 51246, 51247, 51252, 51260, 51262, 51264, 51266, 51267, 51268, 51278, 51287, 51290, 51292, 51294, 51296, 51303, 51305, 51306, 51307, 51309, 51310, 51313, 51314, 51315, 51317, 51319, 51320, 51321, 51323, 51324, 51325, 51326, 51328, 51331, 51332, 51333, 51334, 51335, 51336, 51337, 51338, 51339, 51340, 51341, 51342, 51373, 51388, 51398, 51399, 51400, 51402, 51404, 51411, 51412, 51416, 51420, 51423, 51424, 51425, 51426, 51460, 51462, 51463, 51469, 51474, 51486, 51487, 51505, 51506, 51508, 51512, 51513, 51518, 51519, 51523, 51537]\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por 'itemid' e concatenar as unidades 'valueuom' únicas para cada 'itemid'\n",
    "# Além disso, calcular a média dos valores de 'valuenum'\n",
    "grouped_data = Tabela_final.groupby('itemid').agg({\n",
    "    'valueuom': lambda x: ', '.join(x.dropna().unique()),\n",
    "    'valuenum': 'mean'  \n",
    "}).reset_index()\n",
    "\n",
    "grouped_data.columns = ['itemid', 'valueuom_combined', 'valuenum_mean']\n",
    "\n",
    "# Filtrar os itemid com valuenum_mean igual a zero\n",
    "zero_value_items = grouped_data.query('valuenum_mean == 0')\n",
    "\n",
    "#listando os valores que possuem média igual a zero\n",
    "lista_valores = zero_value_items['itemid'].tolist()\n",
    "\n",
    "print(\"Dados agrupados que possuem média igual a 0:\", lista_valores)\n",
    "\n",
    "# Filtrar os itemid onde valueuom_combined está vazio\n",
    "sem_um = grouped_data[grouped_data['valueuom_combined'] == '']\n",
    "\n",
    "# Listar os itemid com valueuom_combined vazio\n",
    "lista_valores_ausentes = sem_um['itemid'].tolist()\n",
    "\n",
    "# Exibir a lista de itemid com valueuom_combined vazio\n",
    "print(\"Dados agrupados que não possuem unidade de medida:\", lista_valores_ausentes)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirando os valores/unidades de medidas ausentes e unificando as unidades de medida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando os itemid que possuem média igual a 0 e não tem unidade de medida, ou seja, são ausentes \n",
    "valores_para_remover = [\n",
    "    \"50800\", \"50812\", \"50819\", \"50823\", \"50825\", \"50826\", \"50827\", \"50828\", \n",
    "    \"50854\", \"50855\", \"50857\", \"50871\", \"50873\", \"50874\", \"50876\", \"50879\", \n",
    "    \"50880\", \"50887\", \"50919\", \"50920\", \"50932\", \"50933\", \"50939\", \"50940\", \n",
    "    \"50941\", \"50942\", \"50943\", \"50944\", \"50946\", \"50948\", \"50955\", \"50975\", \n",
    "    \"50979\", \"50981\", \"50999\", \"51017\", \"51071\", \"51073\", \"51074\", \"51075\", \n",
    "    \"51076\", \"51079\", \"51086\", \"51090\", \"51091\", \"51092\", \"51098\", \"51103\", \n",
    "    \"51134\", \"51137\", \"51145\", \"51147\", \"51150\", \"51151\", \"51152\", \"51154\", \n",
    "    \"51155\", \"51156\", \"51158\", \"51159\", \"51164\", \"51167\", \"51168\", \"51177\", \n",
    "    \"51178\", \"51182\", \"51183\", \"51184\", \"51188\", \"51191\", \"51192\", \"51193\", \n",
    "    \"51197\", \"51198\", \"51211\", \"51213\", \"51216\", \"51217\", \"51219\", \"51230\", \n",
    "    \"51233\", \"51234\", \"51235\", \"51236\", \"51238\", \"51239\", \"51243\", \"51246\", \n",
    "    \"51247\", \"51252\", \"51260\", \"51262\", \"51264\", \"51266\", \"51267\", \"51268\", \n",
    "    \"51278\", \"51287\", \"51290\", \"51292\", \"51294\", \"51296\", \"51299\", \"51303\", \n",
    "    \"51305\", \"51306\", \"51307\", \"51309\", \"51310\", \"51313\", \"51314\", \"51315\", \n",
    "    \"51317\", \"51319\", \"51320\", \"51321\", \"51323\", \"51324\", \"51325\", \"51326\", \n",
    "    \"51328\", \"51331\", \"51332\", \"51333\", \"51334\", \"51335\", \"51336\", \"51337\", \n",
    "    \"51338\", \"51339\", \"51340\", \"51341\", \"51342\", \"51373\", \"51388\", \"51398\", \n",
    "    \"51399\", \"51400\", \"51402\", \"51404\", \"51411\", \"51412\", \"51416\", \"51420\", \n",
    "    \"51423\", \"51424\", \"51425\", \"51426\", \"51460\", \"51462\", \"51463\", \"51464\", \n",
    "    \"51466\", \"51469\", \"51474\", \"51486\", \"51487\", \"51489\", \"51497\", \"51505\", \n",
    "    \"51506\", \"51508\", \"51512\", \"51513\", \"51517\", \"51518\", \"51519\", \"51523\", \n",
    "    \"51537\"\n",
    "]\n",
    "\n",
    "\n",
    "Tabela_final['itemid'] = Tabela_final['itemid'].astype(str)\n",
    "\n",
    "\n",
    "Tabela_final_2 = Tabela_final[~Tabela_final['itemid'].isin(valores_para_remover)]\n",
    "\n",
    "\n",
    "# #Reutilizando a tabela grouped_data, porém retirando as colunas com média igual 0\n",
    "\n",
    "# # Filtrar os itemid onde valueuom_combined está vazio\n",
    "# sem_um = dados_agrupados[dados_agrupados['valueuom_combined'] == '']\n",
    "\n",
    "# # Listar os itemid com valueuom_combined vazio\n",
    "# lista_valores_ausentes = sem_um['itemid'].tolist()\n",
    "\n",
    "# # Exibir a lista de itemid com valueuom_combined vazio\n",
    "# print(lista_valores_ausentes)\n",
    "\n",
    "# #Retirando os itemid que não unidade de medida, ou seja, são ausentes\n",
    "# valores_para_remover_2 = [\"50819\", \"50823\", \"50825\", \"50826\", \"51087\", \"51094\", \"51237\", \"51240\"]\n",
    "\n",
    "# dados_agrupados.loc[:, 'itemid'] = dados_agrupados['itemid'].astype(str)\n",
    "\n",
    "# # Filtrar os dados, retirando os itemids ausentes\n",
    "# dados_agrupados_2 = dados_agrupados[~dados_agrupados['itemid'].isin(valores_para_remover_2)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando quais unidades de medidas estão sendo usadas para cada exame e colocando eles na mesma unidade de medida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reutilizando a tabela dados_agrupados_2\n",
    "\n",
    "# dados_agrupados_2.to_csv(\"Analisar as colunas 2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo a criação da tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Tabela_final_2 = pd.DataFrame(table.rows, columns=table.field_names)\n",
    "Tabela_final_2.to_csv('Tabela final 2.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possíveis adições que seram feitas usando as tabelas microbiologyevents e drgcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler DRGCODES em chunks e processar cada chunk\n",
    "# for drgcodes_chunk in pd.read_csv(drgcodes_path, chunksize=chunk_size):\n",
    "    \n",
    "#         dados_filtrados_drgcodes.append(drgcodes_chunk)\n",
    "\n",
    "# Ler MICROBIOLOGYEVENTS em chunks e processar cada chunk\n",
    "# for microbiologyevents_chunk in pd.read_csv(microbiologyevents_path, chunksize=chunk_size):\n",
    "    \n",
    "#         dados_filtrados_microbiologyevents.append(microbiologyevents_chunk)\n",
    "\n",
    "# df_filtrado_7 = pd.concat(dados_filtrados_microbiologyevents, ignore_index=True)\n",
    "\n",
    "# df_filtrado_5 = pd.concat(dados_filtrados_drgcodes, ignore_index=True)\n",
    "\n",
    "# df_filtrado_7 = df_filtrado_7.drop(columns=['row_id'])\n",
    "\n",
    "# df_filtrado_5 = df_filtrado_5.drop(columns=['row_id','description','drg_severity','drg_mortality'])\n",
    "\n",
    "#Fazendo o pivoteamento da tabela\n",
    "\n",
    "# df_filtrado_labevents = df_filtrado_labevents.assign(value=1).pivot_table(index='subject_id', columns='itemid', values='value', fill_value=0).reset_index()\n",
    "\n",
    "# df_filtrado_2 = df_filtrado_2.assign(value=1).pivot_table(index='subject_id', columns='religion', values='value', fill_value=0).reset_index()\n",
    "\n",
    "# Junto_6 = pd.merge(Junto_5, df_filtrado_5, on='subject_id', how='inner')\n",
    "\n",
    "# Tabela_final = pd.merge(Junto_6, df_filtrado_7, on='subject_id', how='inner')\n",
    "\n",
    "# aux1 = Tabela_final.assign(value=1).pivot_table(index='subject_id', columns='item_id', values='value', fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "# print(df_filtrado_admissions.columns.tolist())\n",
    "# print(df_filtrado_2.columns.tolist())\n",
    "# print(df_filtrado_labitems.columns.tolist())\n",
    "# print(Tabela_final.columns.tolist())\n",
    "\n",
    "#PCA - scatter plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
